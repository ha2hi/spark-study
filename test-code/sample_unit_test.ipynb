{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/19 23:25:46 WARN Utils: Your hostname, MZC01-HYUCKSANGCHO.local resolves to a loopback address: 127.0.0.1; using 192.168.0.151 instead (on interface en0)\n",
      "25/04/19 23:25:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/19 23:25:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "----------------------------------------------------------------------          \n",
      "Ran 1 test in 7.077s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class PySparkTestCase(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = SparkSession.builder.appName(\"Sample PySpark ETL\").getOrCreate()\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.spark.stop()\n",
    "\n",
    "class SimpleTestCase(PySparkTestCase):\n",
    "    def test_with_df(self):\n",
    "        df = self.spark.createDataFrame(data=[[1, 'a'], [2, 'b']], \n",
    "                                        schema=['c1', 'c2'])\n",
    "        self.assertEqual(df.count(), 2)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], verbosity=0, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/21 21:50:00 WARN Utils: Your hostname, MZC01-HYUCKSANGCHO.local resolves to a loopback address: 127.0.0.1; using 10.10.10.25 instead (on interface en0)\n",
      "25/04/21 21:50:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/21 21:50:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/pyspark/sql/pandas/utils.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(pandas.__version__) < LooseVersion(minimum_pandas_version):\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 359, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 446, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/hs/qgyqqppj281bp7zh9vj3jry40000gn/T/ipykernel_25084/3495253045.py\", line 31, in <module>\n",
      "    unittest.main(argv=[''], verbosity=0, exit=False)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/main.py\", line 101, in __init__\n",
      "    self.runTests()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/main.py\", line 271, in runTests\n",
      "    self.result = testRunner.run(self.test)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/runner.py\", line 184, in run\n",
      "    test(result)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/suite.py\", line 84, in __call__\n",
      "    return self.run(*args, **kwds)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/suite.py\", line 122, in run\n",
      "    test(result)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/suite.py\", line 84, in __call__\n",
      "    return self.run(*args, **kwds)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/suite.py\", line 122, in run\n",
      "    test(result)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/case.py\", line 651, in __call__\n",
      "    return self.run(*args, **kwds)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/case.py\", line 592, in run\n",
      "    self._callTestMethod(testMethod)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/unittest/case.py\", line 550, in _callTestMethod\n",
      "    method()\n",
      "  File \"/var/folders/hs/qgyqqppj281bp7zh9vj3jry40000gn/T/ipykernel_25084/3495253045.py\", line 27, in test_single_space\n",
      "    assertDataFrameEqual(df, df2)\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/pyspark/testing/utils.py\", line 479, in assertDataFrameEqual\n",
      "    import pyspark.pandas as ps\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/pyspark/pandas/__init__.py\", line 35, in <module>\n",
      "    require_minimum_pyarrow_version()\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/pyspark/sql/pandas/utils.py\", line 53, in require_minimum_pyarrow_version\n",
      "    import pyarrow\n",
      "  File \"/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/site-packages/pyarrow/__init__.py\", line 63, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=83, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 61162), raddr=('127.0.0.1', 61161)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/mzc01-hyucksangcho/opt/anaconda3/envs/airflow/lib/python3.9/socket.py:775: ResourceWarning: unclosed <socket.socket fd=83, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 61164), raddr=('127.0.0.1', 61163)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 6.255s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import unittest\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.testing.utils import assertDataFrameEqual\n",
    "\n",
    "class PySparkTestCase(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        cls.spark = SparkSession.builder.appName(\"Testing Pyspark\").getOrCreate()\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        cls.spark.stop()\n",
    "\n",
    "class TestTransformation(PySparkTestCase):\n",
    "    def test_single_space(self):\n",
    "        sample_data = [{\"name\": \"John    D.\", \"age\": 30},\n",
    "                       {\"name\": \"Alice   G.\", \"age\": 25},\n",
    "                       {\"name\": \"Bob  T.\", \"age\": 35},\n",
    "                       {\"name\": \"Eve   A.\", \"age\": 28}]\n",
    "        \n",
    "        df = self.spark.createDataFrame(sample_data)\n",
    "        df2 = self.spark.createDataFrame(sample_data)\n",
    "        df2.drop(\"name\")\n",
    "        \n",
    "        assertDataFrameEqual(df, df2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], verbosity=0, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
